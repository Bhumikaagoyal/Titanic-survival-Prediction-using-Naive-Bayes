# -*- coding: utf-8 -*-
"""titanic-survival-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LbWXCcJdAOejaKg0etQnT-uxQLa3Ro4_
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("/kaggle/input/titanic-data/titanicsurvival.csv")

df.head()

df.tail()

df.info()

df.isna().sum()

df.dropna(inplace=True)

df.isna().sum()

mapping = {'female': 1, 'male': 0}
df['Sex']=df['Sex'].map(mapping)

df.head()

num=[]
cat=[]
for column in df.columns:
    if df[column].nunique()<5:
        cat.append(column)
    else:
        num.append(column)

print(num)

print(cat)

"""**EXPLORATORY DATA ANALYSIS**"""

corr = df.corr()

# Plot correlation heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, cmap='viridis', linewidths=0.5)
plt.title("Correlation Matrix")
plt.show()

plt.figure(figsize=(25,20))
df[num].hist(bins=15, layout=(5, 3))
plt.show()

sns.pairplot(df[num])
plt.show()

plt.figure(figsize=(10,16))
for i , column in enumerate (cat):
    plt.subplot(4,2,i+1)
    ax=sns.countplot(data=df,x=column)
ax.bar_label(ax.containers[0])
plt.show()

plt.figure(figsize=(15,15))
for i,column in enumerate(cat):
    plt.subplot(4,2,i+1)
    df[column].value_counts()
    Property=df[column].value_counts(normalize=True).keys()
    count=df[column].value_counts(normalize=True).values
    Data=pd.DataFrame(zip(Property,count),columns=[column,'Count'])
    n=df[column].nunique()
    l=[0.1 for i in range(n)]
    plt.title(column)
    plt.pie(x=count,labels=Property,autopct='%0.2f%%',shadow=True,radius=1,startangle=90,explode=l)
plt.show()

plt.figure(figsize=(8, 6))
sns.scatterplot(x='Fare', y='Age', hue='Survived', data=df)

"""No relation between fare age and survival"""

plt.figure(figsize=(8, 6))
sns.scatterplot(x='Fare', y='Pclass', hue='Survived', data=df)

"""Females from 1 class and males from 3rd class are more likely to survive"""

# check for outliers in boxplots
for col in num:
        plt.figure(figsize=(10, 6))
        sns.boxplot(x=df[col])
        plt.title(f"Boxplot of {col}")
        plt.show()

from scipy.stats import skew
# Skewness and outlier analysis for numerical columns
for col in num:
    # Skewness analysis
    skewness = skew(df[col])
    print(f"\nSkewness of {col}: {skewness}")

    # Outlier analysis (using IQR method)
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))][col]
    print(f"Outliers in {col}: {outliers.tolist()}")

    # Visualize skewness and outliers
    plt.figure(figsize=(12, 6))

    # Skewness bar plot
    plt.subplot(1, 2, 1)
    sns.barplot(x=[col], y=[skewness])
    plt.title("Skewness of Numerical Columns")
    plt.xlabel("Column")
    plt.ylabel("Skewness")
    plt.xticks(rotation=45)

    # Outlier box plot
    plt.subplot(1, 2, 2)
    sns.boxplot(x=df[col])
    plt.title(f"Outliers in {col}")
    plt.xlabel(col)

    plt.tight_layout()
    plt.show()

# Lists to store variables with outliers and high skewness
variables_with_outliers = []
variables_with_high_skewness = []

# Skewness and outlier analysis for numerical columns
for col in num:
    # Skewness analysis
    skewness = skew(df[col])

    # Outlier analysis (using IQR method)
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))][col]

    # Check for outliers and high skewness
    if len(outliers) > 0:
        variables_with_outliers.append(col)
    if abs(skewness) > 1:  # You can adjust this threshold based on your preference
        variables_with_high_skewness.append(col)

# Print the lists of variables with outliers and high skewness
print("Variables with outliers:", variables_with_outliers)
print("Variables with high skewness:", variables_with_high_skewness)

# Handling outliers by replacing them with median
for col in variables_with_outliers:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Replace outliers with median
    median_val = df[col].median()
    df[col] = df[col].apply(lambda x: median_val if x < lower_bound or x > upper_bound else x)

# Create boxplots for numerical columns
plt.figure(figsize=(12, 8))
df[num].boxplot(rot=90)
plt.title('Boxplots of Numeric Columns')
plt.xlabel('Numeric Columns')
plt.ylabel('Values')
plt.show()

from sklearn.preprocessing import PowerTransformer
# Handling skewness
for col in variables_with_high_skewness:
    # Log transformation for positively skewed variables
    if skew(df[col]) > 1:
        df[col] = np.log1p(df[col])
    # Power transformation for negatively skewed variables
    elif skew(df[col]) < -1:
        pt = PowerTransformer()
        df[col] = pt.fit_transform(df[col].values.reshape(-1, 1))

import math
for i, col in enumerate(num, 1):
    plt.subplot(math.ceil(len(num)/2), 2, i)
    sns.histplot(df[col], kde=True)
    plt.title(col)
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

X = df.drop('Survived',axis='columns')
y=df.Survived

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=0)
print(X_train.shape)
print(X_test.shape)

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train, y_train)

"""**Predicting if the person survived or not**"""

pclassNo = int(input("Enter Person's Pclass number: "))
gender = int(input("Enter Person's Gender 0-female 1-male(0 or 1): "))
age = int(input("Enter Person's Age: "))
fare = float(input("Enter Person's Fare: "))
person = [[pclassNo,gender,age,fare]]
result = model.predict(person)
print(result)

if result == 1:
  print("Person might be Survived")
else:
  print("Person might not be Survived")

y_pred=model.predict(X_test)
print(np.column_stack((y_pred,y_test)))

"""**Accuracy Score**"""

from sklearn.metrics import accuracy_score
print("Accuracy score of model is: {0}%".format(accuracy_score(y_pred,y_test)*100))